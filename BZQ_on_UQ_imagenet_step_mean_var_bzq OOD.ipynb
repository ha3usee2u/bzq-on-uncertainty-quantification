{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.interpolate import interp1d\n",
    "import tensorflow_datasets as tfds\n",
    "from collections import Counter\n",
    "import scipy.ndimage\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import gaussian_kde\n",
    "from numba import jit\n",
    "import torch.nn as nn\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "limit = 1000\n",
    "\n",
    "# bzq modifying\n",
    "len_x_target = 20\n",
    "len_y_target = 20\n",
    "stride_x_target = 10\n",
    "stride_y_target = 10\n",
    "\n",
    "# mean, std proportion\n",
    "alpha = 0.5\n",
    "\n",
    "bins_size = 30  # 統計採樣數\n",
    "poly_degree = bins_size - 1\n",
    "window_size = 1\n",
    "\n",
    "#target image preprocessing\n",
    "angle = 0\n",
    "pixels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MCDropoutResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0),\n",
    "            nn.Linear(self.resnet.fc.in_features, 1000)\n",
    "        )\n",
    "        # 複製原始 ResNet50 的 fc 層權重\n",
    "        original_resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.fc[1].weight.data = original_resnet.fc.weight.data.clone()\n",
    "        self.resnet.fc[1].bias.data = original_resnet.fc.bias.data.clone()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "# 加載預訓練的ResNet50模型\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "#model = MCDropoutResNet()\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到了bzq 正確的函數，拿來做imagenet 正確的預測\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet(original_data, start_x, start_y, len_x, len_y, magnification):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data)\n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] *= magnification\n",
    "    #new_data[start_y:start_y + len_y, start_x:start_x + len_x, :] *= magnification\n",
    "    return new_data\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet_random_global(original_data, start_x, start_y, len_x, len_y, random_num_for_bzq_mask_imagenet):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data)\n",
    "    random_num_for_bzq_mask_imagenet = random_num_for_bzq_mask_imagenet[:, :len_y, :len_x] \n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] = random_num_for_bzq_mask_imagenet\n",
    "    return new_data\n",
    "\n",
    "bzq = []\n",
    "correct_predictions_imagenet = []\n",
    "incorrect_predictions_imagenet = []\n",
    "bzq_imagenet = []\n",
    "\n",
    "#bzq = 0的時候，提取mask之下的softmax\n",
    "correct_predictions_bzq_zero_softmax_mean = []\n",
    "correct_predictions_bzq_zero_softmax_std = []\n",
    "incorrect_predictions_bzq_zero_softmax_mean = []\n",
    "incorrect_predictions_bzq_zero_softmax_std = []\n",
    "\n",
    "# 生成隨機影像，形狀為 (limit, 3, 224, 224)\n",
    "random_images = torch.rand(limit, 3, 224, 224)\n",
    "\n",
    "# 生成存放 -1 的列表\n",
    "negative_labels = [-1] * limit\n",
    "\n",
    "# 建立 test_dataset 為 list of tuples\n",
    "test_dataset = [(random_images[i], negative_labels[i]) for i in range(limit)]\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bzq modifying\n",
    "len_x = len_x_target\n",
    "len_y = len_y_target\n",
    "stride_x = stride_x_target\n",
    "stride_y = stride_y_target\n",
    "batch_size = 1  # 設定批次大小\n",
    "\n",
    "original_predictions_imagenet = []\n",
    "acc_imagenet = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "'''\n",
    "random_num_for_bzq_mask_imagenet = np.random.randint(0, 256, (3, len_y_target, len_x_target)).astype(np.float32) / 255.0\n",
    "bzq_list = []\n",
    "\n",
    "#print(random_num_for_bzq_mask_imagenet)\n",
    "\n",
    "def process_batch(batch_data, len_y, stride_y, len_x, stride_x, device, model, alpha):\n",
    "    bzq = []\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    for i in range(0, 224 - len_y, stride_y):\n",
    "        for j in range(0, 224 - len_x, stride_x):\n",
    "            #print(i, j)\n",
    "            target = torch.from_numpy(single_data_bzq_mask_preprocessing_imagenet_random_global(batch_data, i, j, len_x, len_y, random_num_for_bzq_mask_imagenet)).float().unsqueeze(0).to(device)\n",
    "            #print(target)\n",
    "            output = model(target)\n",
    "            softmax_output = F.softmax(output, dim=1)  # 轉換成機率\n",
    "            predictions.append(softmax_output.cpu().numpy())\n",
    "    \n",
    "    #print(predictions)\n",
    "    # 計算 softmax\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    mean_pred = predictions.mean(axis=0)  # 平均預測\n",
    "    mean_pred = mean_pred.flatten()\n",
    "    #print(np.max(mean_pred))\n",
    "    entropy = -np.sum(mean_pred * np.log(np.clip(mean_pred, 1e-10, 1)), axis=0)  # 防止 log(0) 錯誤\n",
    "\n",
    "    # 計算 bzq\n",
    "    max_bzq_indices = np.argmax(predictions, axis=1)  # NumPy 陣列\n",
    "\n",
    "    # **確保是展平的一維列表**\n",
    "    max_bzq_indices = max_bzq_indices.flatten().tolist()\n",
    "    counter = Counter(max_bzq_indices) \n",
    "\n",
    "    most_common_num, most_common_count = counter.most_common(1)[0]\n",
    "    temp = predictions[:, most_common_num]\n",
    "\n",
    "    bzq.append(alpha * np.mean(temp) + (1 - alpha) * (2.0 / np.pi * np.arctan(1.0 / np.std(temp))))\n",
    "\n",
    "    return bzq, temp, entropy\n",
    "\n",
    "entropies = []\n",
    "with torch.no_grad():\n",
    "    for start in range(0, len(test_dataset), batch_size):\n",
    "        end = min(start + batch_size, len(test_dataset))\n",
    "        batch_data_labels = [test_dataset[i] for i in range(start, end)]\n",
    "        batch_data, batch_labels = zip(*batch_data_labels)\n",
    "        \n",
    "        for k in range(len(batch_data)):\n",
    "            if len(batch_data[k]) > 0:\n",
    "                bzq, temp, ent = process_batch(\n",
    "                    batch_data[k], len_y, stride_y, len_x, stride_x, device, model, alpha\n",
    "                )\n",
    "                entropies.append(ent)\n",
    "                \n",
    "\n",
    "bzq_imagenet = np.array(bzq_list)\n",
    "'''\n",
    "# 初始化隨機數陣列\n",
    "random_num_for_bzq_mask_imagenet = np.random.randint(0, 256, (3, len_y_target, len_x_target)).astype(np.float32) / 255.0\n",
    "bzq_list = []\n",
    "\n",
    "def process_batch(batch_data, len_y, stride_y, len_x, stride_x, device, model, alpha):\n",
    "    \"\"\"處理 batch 以計算 bzq、temp 及 entropy\"\"\"\n",
    "    predictions = [\n",
    "        F.softmax(\n",
    "            model(\n",
    "                torch.from_numpy(\n",
    "                    single_data_bzq_mask_preprocessing_imagenet_random_global(\n",
    "                        batch_data, i, j, len_x, len_y, random_num_for_bzq_mask_imagenet\n",
    "                    )\n",
    "                ).float().unsqueeze(0).to(device)\n",
    "            ),\n",
    "            dim=1\n",
    "        ).cpu().numpy()\n",
    "        for i in range(0, 224 - len_y, stride_y)\n",
    "        for j in range(0, 224 - len_x, stride_x)\n",
    "    ]\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # 計算 entropy\n",
    "    mean_pred = predictions.mean(axis=0).flatten()\n",
    "    entropy = -np.sum(mean_pred * np.log(np.clip(mean_pred, 1e-10, 1)))\n",
    "\n",
    "    # 計算 bzq\n",
    "    max_bzq_indices = np.argmax(predictions, axis=1).flatten()\n",
    "    most_common_num, _ = Counter(max_bzq_indices).most_common(1)[0]\n",
    "    temp = predictions[:, most_common_num]\n",
    "\n",
    "    bzq = alpha * np.mean(temp) + (1 - alpha) * (2.0 / np.pi * np.arctan(1.0 / np.std(temp)))\n",
    "\n",
    "    return bzq, temp, entropy\n",
    "\n",
    "# 計算 entropy\n",
    "entropies = []\n",
    "with torch.no_grad():\n",
    "    for start in range(0, len(test_dataset), batch_size):\n",
    "        end = min(start + batch_size, len(test_dataset))\n",
    "        batch_data_labels = [test_dataset[i] for i in range(start, end)]\n",
    "        batch_data, _ = zip(*batch_data_labels)\n",
    "\n",
    "        entropies.extend(\n",
    "            process_batch(batch_data[k], len_y, stride_y, len_x, stride_x, device, model, alpha)[2]\n",
    "            for k in range(len(batch_data)) if batch_data[k].numel() > 0  # 確保 Tensor 不為空\n",
    "        )\n",
    "\n",
    "bzq_imagenet = np.array(bzq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[0][0].size())\n",
    "# 計算熵的分佈（分桶）\n",
    "bins = np.linspace(min(entropies), max(entropies), 15) \n",
    "hist, bin_edges = np.histogram(entropies, bins=bins)  # 計算直方圖數據\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # 計算每個 bin 的中心點\n",
    "\n",
    "# 繪製折線圖\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bin_centers, hist, linestyle='-', marker='o')\n",
    "\n",
    "# 設定標題與軸標籤\n",
    "plt.title(\"Entropy Distribution\")\n",
    "plt.xlabel(\"Entropy\")\n",
    "plt.ylabel(\"# of Examples\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
