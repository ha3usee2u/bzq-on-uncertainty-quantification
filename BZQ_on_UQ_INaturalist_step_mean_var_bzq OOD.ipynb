{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.interpolate import interp1d\n",
    "import tensorflow_datasets as tfds\n",
    "from collections import Counter\n",
    "import scipy.ndimage\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import gaussian_kde\n",
    "from numba import jit\n",
    "from torchvision.datasets import INaturalist\n",
    "from tqdm import tqdm  # 導入進度條庫\n",
    "import json\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "limit = 1000\n",
    "\n",
    "# bzq modifying\n",
    "len_x_target = 20\n",
    "len_y_target = 20\n",
    "stride_x_target = 10\n",
    "stride_y_target = 10\n",
    "\n",
    "# mean, std proportion\n",
    "alpha = 0.5\n",
    "\n",
    "bins_size = 30  # 統計採樣數\n",
    "poly_degree = bins_size - 1\n",
    "window_size = 1\n",
    "\n",
    "#target image preprocessing\n",
    "angle = 0\n",
    "pixels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, initial_lr):\n",
    "    if epoch <= 5:\n",
    "        lr = initial_lr * epoch / 5\n",
    "    elif epoch > 160:\n",
    "        lr = initial_lr * 0.01\n",
    "    elif epoch > 75:\n",
    "        lr = initial_lr * 0.1\n",
    "    else:\n",
    "        lr = initial_lr\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.RandomCrop((224, 224)),  # 隨機裁剪至 224x224\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),  # 確保所有圖像都是 RGB 格式\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),  # 機率為 50% 隨機水平翻轉\n",
    "    transforms.ToTensor(),  # 將圖像轉換為 Tensor\n",
    "    transforms.Normalize(mean=[0.466, 0.471, 0.380], std=[0.195, 0.194, 0.192]),  # 標準化\n",
    "])\n",
    "\n",
    "dataset = INaturalist(\n",
    "    root=\"/home/a/bzq_on_confidence/Confidence2022/notebook/confident/grocery/iNaturalist2018/train_val2018\",  # 資料集存儲的根目錄\n",
    "    version=\"2018\",          # 使用 2018 版本\n",
    "    target_type=\"super\",     # 使用超級分類\n",
    "    transform=transform,     # 圖像增強\n",
    "    download=False           # 如果需要下載設置為 True\n",
    "    )\n",
    "\n",
    "model = models.resnet50(weights=False)\n",
    "# 獲取原始模型的輸入特徵大小\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# 修改全連接層輸出至 14 類別（對應 iNaturalist 2018 的 super category）\n",
    "model.fc = torch.nn.Linear(num_features, 14)\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "num_epochs = 50\n",
    "\n",
    "if os.path.exists(f\"resnet50_epoch_{num_epochs}.pth\"):\n",
    "    # 加載保存的權重\n",
    "    checkpoint_path = f\"resnet50_epoch_{num_epochs}.pth\"  # 你的權重檔案路徑\n",
    "    model.load_state_dict(torch.load(checkpoint_path))  # 讀取權重並更新模型參數\n",
    "\n",
    "    # 切換模型到評估模式\n",
    "    model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到了bzq 正確的函數，拿來做imagenet 正確的預測\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet(original_data, start_x, start_y, len_x, len_y, magnification):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data.cpu())\n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] *= magnification\n",
    "    #new_data[start_y:start_y + len_y, start_x:start_x + len_x, :] *= magnification\n",
    "    return new_data\n",
    "\n",
    "\n",
    "#print(random_num_for_bzq_mask_imagenet)\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet_random_global(original_data, start_x, start_y, len_x, len_y, random_num_for_bzq_mask_imagenet):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data.cpu().numpy())\n",
    "    new_data = new_data.squeeze(0)\n",
    "    random_num_for_bzq_mask_imagenet = random_num_for_bzq_mask_imagenet[:, :len_y, :len_x] \n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] = random_num_for_bzq_mask_imagenet\n",
    "    return new_data\n",
    "\n",
    "\n",
    "bzq = []\n",
    "correct_predictions_imagenet = []\n",
    "incorrect_predictions_imagenet = []\n",
    "bzq_imagenet = []\n",
    "\n",
    "#bzq = 0的時候，提取mask之下的softmax\n",
    "correct_predictions_bzq_zero_softmax_mean = []\n",
    "correct_predictions_bzq_zero_softmax_std = []\n",
    "incorrect_predictions_bzq_zero_softmax_mean = []\n",
    "incorrect_predictions_bzq_zero_softmax_std = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, limit):\n",
    "        self.limit = limit\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.limit\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.randn(3, 224, 224)\n",
    "        label = torch.tensor(-1)\n",
    "        return img, label\n",
    "\n",
    "test_dataset = DummyDataset(limit)\n",
    "\n",
    "# 創建 DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "for img, lab in test_loader:\n",
    "    print(img.shape, lab.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_vanilla = []\n",
    "# 預測並顯示分數\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 計算Softmax並獲取最大值\n",
    "        softmax_probs = F.softmax(outputs, dim=1)  # Softmax值\n",
    "        max_probs, predicted = torch.max(softmax_probs, 1)\n",
    "\n",
    "        conf_vanilla.extend(max_probs.cpu().numpy()) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #print(model)\n",
    "        #print(labels, predicted)\n",
    "        \n",
    "conf_vanilla = np.array(conf_vanilla)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bzq modifying\n",
    "len_x = len_x_target\n",
    "len_y = len_y_target\n",
    "stride_x = stride_x_target\n",
    "stride_y = stride_y_target\n",
    "batch_size = 1  # 設定批次大小\n",
    "\n",
    "original_predictions_imagenet = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.to(device).float()\n",
    "        batch_predictions_imagenet = model(batch_data).cpu().numpy()\n",
    "        original_predictions_imagenet.append(batch_predictions_imagenet)\n",
    "\n",
    "original_predictions_imagenet = np.vstack(original_predictions_imagenet)\n",
    "\n",
    "# 使用正確的方式來訪問 test_dataset 中的標籤\n",
    "test_labels = [test_dataset[i][1] for i in range(len(test_dataset))]\n",
    "\n",
    "predicted_labels = np.argmax(original_predictions_imagenet, axis=1)\n",
    "correct_indices = np.where(predicted_labels == np.array(test_labels))[0]\n",
    "incorrect_indices = np.where(predicted_labels != np.array(test_labels))[0]\n",
    "\n",
    "correct_predictions_imagenet.extend(correct_indices.tolist())\n",
    "incorrect_predictions_imagenet.extend(incorrect_indices.tolist())\n",
    "\n",
    "print(f\"{len(correct_predictions_imagenet)}, {len(incorrect_predictions_imagenet)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random_num_for_bzq_mask_imagenet = np.random.randint(0, 256, (3, len_y_target, len_x_target)).astype(np.float32) / 255.0\n",
    "\n",
    "def compute_entropy(softmax_predictions):\n",
    "    # 為了數值穩定，加上 ε 避免 log(0)\n",
    "    eps = 1e-8\n",
    "    softmax_predictions = torch.mean(softmax_predictions, dim=0)\n",
    "    log_probs = torch.log(softmax_predictions + eps)\n",
    "    entropy = -torch.sum(softmax_predictions * log_probs)\n",
    "    return entropy\n",
    "\n",
    "def process_batch(batch_data, batch_labels, len_y, stride_y, len_x, stride_x, device, model, alpha, bzq):\n",
    "    if len(batch_data) == 0:\n",
    "        return bzq, np.array([])\n",
    "\n",
    "    targets = []\n",
    "\n",
    "    for i in range(0, 224 - len_y, stride_y):\n",
    "        for j in range(0, 224 - len_x, stride_x):\n",
    "            #target = single_data_bzq_mask_preprocessing_imagenet(batch_data, i, j, len_x, len_y, 0)\n",
    "            target = single_data_bzq_mask_preprocessing_imagenet_random_global(batch_data, i, j, len_x, len_y, random_num_for_bzq_mask_imagenet)\n",
    "            targets.append(target)\n",
    "    \n",
    "    targets_tensor = torch.from_numpy(np.vstack(targets).reshape(-1, 3, 224, 224)).float().to(device)\n",
    "    predictions = model(targets_tensor)\n",
    "    \n",
    "    #temp, _ = torch.max(F.softmax(predictions), dim=1)\n",
    "    #temp = temp.cpu().numpy()\n",
    "    \n",
    "    max_bzq_indices = torch.argmax(predictions, dim=1).cpu().numpy()\n",
    "    \n",
    "    # 計算 softmax\n",
    "    softmax_predictions = F.softmax(predictions, dim=1)\n",
    "\n",
    "    #print(softmax_predictions.shape)\n",
    "\n",
    "    entropy = compute_entropy(softmax_predictions)\n",
    "\n",
    "    labels = batch_labels\n",
    "\n",
    "    counter = Counter(max_bzq_indices)\n",
    "    most_common_num, most_common_count = counter.most_common(1)[0]\n",
    "    \n",
    "    temp = softmax_predictions[:, most_common_num].cpu().numpy()\n",
    "    \n",
    "    bzq.append(alpha * np.mean(temp) + (1 - alpha) * (2.0 / np.pi * np.arctan(1.0 / np.std(temp))))\n",
    "\n",
    "    return bzq, temp, entropy.cpu()\n",
    "\n",
    "entropies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.to(device)  # 將批次影像搬到指定裝置\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        if len(batch_data) > 0:\n",
    "            bzq, temp, entropy = process_batch(\n",
    "                batch_data, batch_labels, len_y, stride_y, len_x, stride_x, device, model, alpha, bzq\n",
    "            )\n",
    "            entropies.append(entropy)\n",
    "            # 影像預處理\n",
    "            original_data = single_data_bzq_mask_preprocessing_imagenet(batch_data, 0, 0, 0, 0, 0)\n",
    "            original_prediction = model(torch.tensor(original_data.reshape(-1, 3, 224, 224)).float().to(device))\n",
    "            max_original_index = torch.argmax(original_prediction).item()\n",
    "\n",
    "            # 根據 `bzq` 值分類統計\n",
    "            if bzq[-1] == 0.0:\n",
    "                if (len(bzq) - 1) in correct_predictions_imagenet:\n",
    "                    correct_predictions_bzq_zero_softmax_mean.append(np.mean(temp))\n",
    "                    correct_predictions_bzq_zero_softmax_std.append(np.std(temp))\n",
    "                else:\n",
    "                    incorrect_predictions_bzq_zero_softmax_mean.append(np.mean(temp))\n",
    "                    incorrect_predictions_bzq_zero_softmax_std.append(np.std(temp))\n",
    "\n",
    "bzq_imagenet = np.array(bzq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 計算熵的分佈（分桶）\n",
    "bins = np.linspace(min(entropies), max(entropies), 15) \n",
    "hist, bin_edges = np.histogram(entropies, bins=bins)  # 計算直方圖數據\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # 計算每個 bin 的中心點\n",
    "print(np.median(entropies), np.std(entropies))\n",
    "# 繪製折線圖\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bin_centers, hist, linestyle='-', marker='o')\n",
    "\n",
    "# 設定標題與軸標籤\n",
    "plt.title(\"Entropy Distribution\")\n",
    "plt.xlabel(\"Entropy\")\n",
    "plt.ylabel(\"# of Examples\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
