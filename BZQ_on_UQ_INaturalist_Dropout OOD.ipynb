{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.interpolate import interp1d\n",
    "import tensorflow_datasets as tfds\n",
    "from collections import Counter\n",
    "import scipy.ndimage\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import gaussian_kde\n",
    "from numba import jit\n",
    "from torchvision.datasets import INaturalist\n",
    "from tqdm import tqdm  # 導入進度條庫\n",
    "import json\n",
    "import torch.nn as nn\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "limit = 1000\n",
    "num_samples = 1  # Monte-Carlo Dropout 取樣次數\n",
    "dropout_rate = 0.0\n",
    "\n",
    "bins_size = 30  # 統計採樣數\n",
    "poly_degree = bins_size - 1\n",
    "window_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class MCDropoutResNet(nn.Module):\n",
    "    def __init__(self, dropout_p):\n",
    "        super().__init__()\n",
    "        # **載入與 checkpoint 匹配的 ResNet50**\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "\n",
    "        # **修改 FC 層輸出至 14 類別**\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, 14)  # 確保輸出為 14 類別\n",
    "\n",
    "        # **Dropout 參數**\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = nn.Dropout(p=self.dropout_p)(x)  # 在 layer1 之後插入 Dropout\n",
    "\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = nn.Dropout(p=self.dropout_p)(x)  # 在 layer2 之後插入 Dropout\n",
    "\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = nn.Dropout(p=self.dropout_p)(x)  # 在 layer3 之後插入 Dropout\n",
    "\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = nn.Dropout(p=self.dropout_p)(x)  # 在 layer4 之後插入 Dropout\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def enable_dropout(self):\n",
    "        \"\"\"啟用 Dropout，使其在推論時仍作用\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Dropout):\n",
    "                m.train()  # 在推論時啟用 Dropout\n",
    "\n",
    "# **初始化模型**\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MCDropoutResNet(dropout_p=dropout_rate).to(device)\n",
    "\n",
    "# **載入權重**\n",
    "checkpoint_path = \"resnet50_epoch_50.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# **為所有鍵值新增 \"resnet.\" 前綴**\n",
    "new_checkpoint = {f\"resnet.{k}\": v for k, v in checkpoint.items()}  # 加上前綴\n",
    "model.load_state_dict(new_checkpoint)\n",
    "\n",
    "model.eval()  # 切換至推論模式\n",
    "if dropout_rate > 0.0:\n",
    "    print(\"enable dropout\")\n",
    "    model.enable_dropout()  # 啟用 MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到了bzq 正確的函數，拿來做imagenet 正確的預測\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet(original_data, start_x, start_y, len_x, len_y, magnification):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data.cpu())\n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] *= magnification\n",
    "    #new_data[start_y:start_y + len_y, start_x:start_x + len_x, :] *= magnification\n",
    "    return new_data\n",
    "\n",
    "\n",
    "#print(random_num_for_bzq_mask_imagenet)\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet_random_global(original_data, start_x, start_y, len_x, len_y, random_num_for_bzq_mask_imagenet):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data.cpu().numpy())\n",
    "    new_data = new_data.squeeze(0)\n",
    "    random_num_for_bzq_mask_imagenet = random_num_for_bzq_mask_imagenet[:, :len_y, :len_x] \n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] = random_num_for_bzq_mask_imagenet\n",
    "    return new_data\n",
    "\n",
    "\n",
    "bzq = []\n",
    "correct_predictions_imagenet = []\n",
    "incorrect_predictions_imagenet = []\n",
    "bzq_imagenet = []\n",
    "\n",
    "#bzq = 0的時候，提取mask之下的softmax\n",
    "correct_predictions_bzq_zero_softmax_mean = []\n",
    "correct_predictions_bzq_zero_softmax_std = []\n",
    "incorrect_predictions_bzq_zero_softmax_mean = []\n",
    "incorrect_predictions_bzq_zero_softmax_std = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, limit):\n",
    "        self.limit = limit\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.limit\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.randn(3, 224, 224)\n",
    "        label = torch.tensor(-1)    \n",
    "        return img, label\n",
    "\n",
    "test_dataset = DummyDataset(limit)\n",
    "\n",
    "# 創建 DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=6, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_vanilla = []\n",
    "# 預測並顯示分數\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 計算Softmax並獲取最大值\n",
    "        softmax_probs = F.softmax(outputs, dim=1)  # Softmax值\n",
    "        max_probs, predicted = torch.max(softmax_probs, 1)\n",
    "\n",
    "        conf_vanilla.extend(max_probs.cpu().numpy()) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #print(model)\n",
    "        #print(labels, predicted)\n",
    "        \n",
    "conf_vanilla = np.array(conf_vanilla)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_predictions_imagenet = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.to(device).float()\n",
    "        batch_predictions_imagenet = model(batch_data).cpu().numpy()\n",
    "        original_predictions_imagenet.append(batch_predictions_imagenet)\n",
    "\n",
    "original_predictions_imagenet = np.vstack(original_predictions_imagenet)\n",
    "\n",
    "# 使用正確的方式來訪問 test_dataset 中的標籤\n",
    "test_labels = [test_dataset[i][1] for i in range(len(test_dataset))]\n",
    "\n",
    "predicted_labels = np.argmax(original_predictions_imagenet, axis=1)\n",
    "correct_indices = np.where(predicted_labels == np.array(test_labels))[0]\n",
    "incorrect_indices = np.where(predicted_labels != np.array(test_labels))[0]\n",
    "\n",
    "correct_predictions_imagenet.extend(correct_indices.tolist())\n",
    "incorrect_predictions_imagenet.extend(incorrect_indices.tolist())\n",
    "\n",
    "print(f\"{len(correct_predictions_imagenet)}, {len(incorrect_predictions_imagenet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random_num_for_bzq_mask_imagenet = np.random.randint(0, 256, (3, 0, 0)).astype(np.float32) / 255.0\n",
    "\n",
    "def compute_entropy(softmax_predictions):\n",
    "    # 為了數值穩定，加上 ε 避免 log(0)\n",
    "    eps = 1e-8\n",
    "    \n",
    "    log_probs = torch.log(softmax_predictions + eps)\n",
    "    entropy = -torch.sum(softmax_predictions * log_probs)\n",
    "    return entropy\n",
    "\n",
    "def process_batch(batch_data, batch_label, device, model, bzq, mc_samples):\n",
    "    if len(batch_data) == 0:\n",
    "        return bzq, np.array([])\n",
    "\n",
    "    mc_predictions = []\n",
    "    \n",
    "    for _ in range(mc_samples):  # **進行多次 forward**\n",
    "        predictions = model(batch_data.float())\n",
    "        mc_predictions.append(predictions.unsqueeze(0))  # **儲存 MC Dropout 結果**\n",
    "\n",
    "    # **堆疊所有 MC Dropout 結果**\n",
    "    mc_predictions = torch.cat(mc_predictions, dim=0)  # (mc_samples, batch_size, num_classes)\n",
    "\n",
    "    # **計算 MC Dropout 之後的平均**\n",
    "    mean_predictions = mc_predictions.mean(dim=0)  # 均值 (batch_size, num_classes)\n",
    "\n",
    "    max_bzq_indices = torch.argmax(mean_predictions, dim=1).cpu().numpy()\n",
    "\n",
    "    # **計算 softmax**\n",
    "    softmax_predictions = F.softmax(mean_predictions, dim=1)\n",
    "\n",
    "    #print(softmax_predictions.shape)\n",
    "    entropy = compute_entropy(softmax_predictions)\n",
    "\n",
    "    labels = batch_label\n",
    "\n",
    "    counter = Counter(max_bzq_indices)\n",
    "    most_common_num, most_common_count = counter.most_common(1)[0]\n",
    "    \n",
    "    temp = softmax_predictions[:, most_common_num].cpu().numpy()\n",
    "\n",
    "    return temp, entropy.cpu()\n",
    "\n",
    "entropies = []\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_label in test_loader:\n",
    "        batch_data = batch_data.to(device)  # 將批次影像搬到指定裝置\n",
    "        batch_label = batch_label.to(device)\n",
    "        \n",
    "        if len(batch_data) > 0:\n",
    "            bzq, entropy = process_batch(\n",
    "                batch_data, batch_label, device, model, bzq, num_samples\n",
    "            )\n",
    "            bzq_imagenet.append(bzq)\n",
    "            entropies.append(entropy)\n",
    "\n",
    "            # 影像預處理\n",
    "            original_data = single_data_bzq_mask_preprocessing_imagenet(batch_data, 0, 0, 0, 0, 0)\n",
    "            original_prediction = model(torch.tensor(original_data.reshape(-1, 3, 224, 224)).float().to(device))\n",
    "            max_original_index = torch.argmax(original_prediction).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算熵的分佈（分桶）\n",
    "bins = np.linspace(min(entropies), max(entropies), 15) \n",
    "hist, bin_edges = np.histogram(entropies, bins=bins)  # 計算直方圖數據\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # 計算每個 bin 的中心點\n",
    "print(np.median(entropies), np.std(entropies))\n",
    "# 繪製折線圖\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bin_centers, hist, linestyle='-', marker='o')\n",
    "\n",
    "# 設定標題與軸標籤\n",
    "plt.title(\"Entropy Distribution\")\n",
    "plt.xlabel(\"Entropy\")\n",
    "plt.ylabel(\"# of Examples\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
