{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.interpolate import interp1d\n",
    "import tensorflow_datasets as tfds\n",
    "from collections import Counter\n",
    "import scipy.ndimage\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import gaussian_kde\n",
    "from numba import jit\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "limit = 10000\n",
    "\n",
    "# bzq modifying\n",
    "len_x_target = 20\n",
    "len_y_target = 20\n",
    "stride_x_target = 10\n",
    "stride_y_target = 10\n",
    "\n",
    "# mean, std proportion\n",
    "alpha = 0.5\n",
    "\n",
    "bins_size = 30  # 統計採樣數\n",
    "poly_degree = bins_size - 1\n",
    "window_size = 1\n",
    "\n",
    "#target image preprocessing\n",
    "angle = 0\n",
    "pixels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None, limit=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        with open(labels_file, 'r') as f:\n",
    "            self.labels = [int(line.split()[1]) for line in f.readlines()]\n",
    "        self.img_names = sorted(os.listdir(img_dir))\n",
    "        \n",
    "        if limit:\n",
    "            indices = np.random.choice(len(self.img_names), limit, replace=False) \n",
    "            self.img_names = [self.img_names[i] for i in indices] \n",
    "            self.labels = [self.labels[i] for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class CustomImageDatasetC(Dataset): # for corruptions\n",
    "    def __init__(self, img_dirs, labels_file, transform=None, limit=None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.transform = transform\n",
    "        self.img_names = []\n",
    "        self.labels = {}\n",
    "\n",
    "        # **載入標籤**\n",
    "        with open(labels_file, 'r') as f:\n",
    "            raw_labels = [line.strip().split() for line in f.readlines()]  # 讀取完整標籤文件\n",
    "            self.labels = {entry[0]: int(entry[-1]) for entry in raw_labels}  # 影像檔名 → 標籤對應字典\n",
    "\n",
    "        # **載入影像並匹配標籤**\n",
    "        total_images = []\n",
    "        total_labels = []\n",
    "\n",
    "        for img_dir in img_dirs:\n",
    "            if os.path.exists(img_dir):\n",
    "                img_names_in_dir = sorted(os.listdir(img_dir))\n",
    "\n",
    "                # **每個擾動級別獨立選取 limit 張**\n",
    "                if limit and len(img_names_in_dir) > limit:\n",
    "                    img_names_in_dir = img_names_in_dir[:limit]\n",
    "\n",
    "                # **確保影像有對應標籤**\n",
    "                valid_images = [(img_dir, img_name) for img_name in img_names_in_dir if img_name in self.labels]\n",
    "\n",
    "                # **確保標籤數量匹配影像**\n",
    "                valid_labels = [self.labels[img_name] for _, img_name in valid_images]\n",
    "\n",
    "                total_images.extend(valid_images)\n",
    "                total_labels.extend(valid_labels)\n",
    "\n",
    "        self.img_names = total_images\n",
    "        self.labels = total_labels  # 確保影像與標籤數量完全一致\n",
    "\n",
    "        # **檢查是否仍然不匹配**\n",
    "        if len(self.img_names) != len(self.labels):\n",
    "            print(f\"Warning: Mismatch! {len(self.img_names)} images vs. {len(self.labels)} labels.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_dir, img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "        # **正確對應標籤**\n",
    "        label = self.labels[idx]  # 直接從列表索引獲取標籤\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "# 設置設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定義圖像轉換\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加載預訓練的ResNet50模型\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到了bzq 正確的函數，拿來做imagenet 正確的預測\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet(original_data, start_x, start_y, len_x, len_y, magnification):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data)\n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] *= magnification\n",
    "    #new_data[start_y:start_y + len_y, start_x:start_x + len_x, :] *= magnification\n",
    "    return new_data\n",
    "\n",
    "\n",
    "#print(random_num_for_bzq_mask_imagenet)\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet_random_global(original_data, start_x, start_y, len_x, len_y, random_num_for_bzq_mask_imagenet):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data)\n",
    "    random_num_for_bzq_mask_imagenet = random_num_for_bzq_mask_imagenet[:, :len_y, :len_x] \n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] = random_num_for_bzq_mask_imagenet\n",
    "    return new_data\n",
    "\n",
    "bzq = []\n",
    "correct_predictions_imagenet = []\n",
    "incorrect_predictions_imagenet = []\n",
    "bzq_imagenet = []\n",
    "\n",
    "#bzq = 0的時候，提取mask之下的softmax\n",
    "correct_predictions_bzq_zero_softmax_mean = []\n",
    "correct_predictions_bzq_zero_softmax_std = []\n",
    "incorrect_predictions_bzq_zero_softmax_mean = []\n",
    "incorrect_predictions_bzq_zero_softmax_std = []\n",
    "\n",
    "\n",
    "corruption_levels = ['1', '2', '3', '4', '5']\n",
    "corruption_types = [\n",
    "    'brightness', 'contrast', 'defocus_blur', 'elastic_transform', 'fog', 'frost',\n",
    "    'gaussian_blur', 'gaussian_noise', 'glass_blur', 'impulse_noise', 'pixelate',\n",
    "    'saturate', 'shot_noise', 'spatter', 'speckle_noise', 'zoom_blur'\n",
    "]\n",
    "\n",
    "#corruption_levels = ['3']\n",
    "#corruption_types = ['gaussian_blur']\n",
    "\n",
    "# 建立所有可能的 img_dirs\n",
    "img_dirs = []\n",
    "for level in corruption_levels:\n",
    "    for corruption in corruption_types:\n",
    "        img_dirs.append(f\"/home/a/bzq_on_confidence/Confidence2022/notebook/confident/grocery/imagenetc/{corruption}/{level}\")\n",
    "\n",
    "# 建立 dataset，載入所有 corruption level 的影像\n",
    "test_dataset_c = CustomImageDatasetC(\n",
    "    img_dirs,\n",
    "    \"/home/a/bzq_on_confidence/Confidence2022/notebook/confident/grocery/ILSVRC2012_validation_ground_truth.txt\",\n",
    "    transform=transform,\n",
    "    limit=limit\n",
    ")\n",
    "\n",
    "test_dataset = CustomImageDataset(\"/home/a/bzq_on_confidence/Confidence2022/notebook/confident/grocery/ILSVRC2012_img_val\", \n",
    "                                 \"/home/a/bzq_on_confidence/Confidence2022/notebook/confident/grocery/ILSVRC2012_validation_ground_truth.txt\", \n",
    "                                 transform=transform, \n",
    "                                 limit=limit)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 預測並顯示分數\n",
    "'''\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bzq modifying\n",
    "len_x = len_x_target\n",
    "len_y = len_y_target\n",
    "stride_x = stride_x_target\n",
    "stride_y = stride_y_target\n",
    "batch_size = 1  # 設定批次大小\n",
    "\n",
    "original_predictions_imagenet = []\n",
    "acc_imagenet = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_predictions_imagenet = model(batch_data).cpu().numpy()\n",
    "        original_predictions_imagenet.append(batch_predictions_imagenet)\n",
    "\n",
    "original_predictions_imagenet = np.vstack(original_predictions_imagenet)\n",
    "\n",
    "# 使用正確的方式來訪問 test_dataset 中的標籤\n",
    "test_labels = [test_dataset[i][1] for i in range(len(test_dataset))]\n",
    "\n",
    "predicted_labels = np.argmax(original_predictions_imagenet, axis=1)\n",
    "correct_indices = np.where(predicted_labels == np.array(test_labels))[0]\n",
    "incorrect_indices = np.where(predicted_labels != np.array(test_labels))[0]\n",
    "\n",
    "correct_predictions_imagenet.extend(correct_indices.tolist())\n",
    "incorrect_predictions_imagenet.extend(incorrect_indices.tolist())\n",
    "\n",
    "for i in range(len(predicted_labels)):\n",
    "    if predicted_labels[i] == test_labels[i]:\n",
    "        acc_imagenet.append(1)\n",
    "    else:\n",
    "        acc_imagenet.append(0)\n",
    "\n",
    "print(f\"{len(correct_predictions_imagenet)}, {len(incorrect_predictions_imagenet)}\")\n",
    "\n",
    "'''original_predictions_imagenet = []\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        batch_predictions_imagenet = model(batch_data)\n",
    "        original_predictions_imagenet.append(batch_predictions_imagenet.cpu().numpy())\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    if np.argmax(original_predictions_imagenet[i]) == test_dataset[i][1]:\n",
    "        correct_predictions_imagenet.append(i)\n",
    "    else:\n",
    "        incorrect_predictions_imagenet.append(i)\n",
    "\n",
    "original_predictions_imagenet = np.vstack(original_predictions_imagenet)\n",
    "\n",
    "print(f\"{len(correct_predictions_imagenet)}, {len(incorrect_predictions_imagenet)}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random_num_for_bzq_mask_imagenet = np.random.randint(0, 256, (3, len_y_target, len_x_target)).astype(np.float32) / 255.0\n",
    "bzq_list = []\n",
    "brier_scores = []\n",
    "uncertainties = []\n",
    "resolutions = []\n",
    "reliabilities = []\n",
    "nll_losses = []\n",
    "\n",
    "def brier_score_decomposition(predictions, labels, num_classes=1000):\n",
    "    \"\"\"\n",
    "    計算 Brier Score 並拆解為 Uncertainty, Resolution, Reliability\n",
    "    predictions: (batch_size, num_classes) - softmax 輸出\n",
    "    \"\"\"\n",
    "    # 轉換標籤為 One-Hot 編碼\n",
    "    labels_one_hot = torch.nn.functional.one_hot(labels, num_classes).float()\n",
    "    \n",
    "    # 計算 Brier Score\n",
    "    brier_score = torch.mean(torch.sum((predictions - labels_one_hot) ** 2, dim=1))\n",
    "\n",
    "    # 計算 Uncertainty\n",
    "    marginal_probs = torch.mean(predictions, dim=0)  # 平均預測機率\n",
    "    uncertainty = torch.sum(marginal_probs * (1 - marginal_probs))\n",
    "\n",
    "    # 計算 Resolution\n",
    "    mean_class_probs = torch.mean(labels_one_hot, dim=0)\n",
    "    resolution = torch.sum(mean_class_probs * (1 - mean_class_probs))\n",
    "\n",
    "    # 計算 Reliability\n",
    "    reliability = brier_score - uncertainty + resolution  # 修正計算方式\n",
    "\n",
    "    return {\n",
    "        \"Brier Score\": brier_score.item(),\n",
    "        \"Uncertainty\": uncertainty.item(),\n",
    "        \"Resolution\": resolution.item(),\n",
    "        \"Reliability\": reliability.item()\n",
    "    }\n",
    "\n",
    "def compute_nll(predictions, labels):\n",
    "    \"\"\"\n",
    "    計算 Negative Log-Likelihood (NLL)\n",
    "    predictions: shape (batch_size, num_classes) - softmax 輸出\n",
    "    labels: shape (batch_size) - 正確的標籤\n",
    "    \"\"\"\n",
    "    log_probs = torch.log(predictions)\n",
    "\n",
    "    labels = labels.expand(predictions.shape[0])\n",
    "    nll_loss = F.nll_loss(log_probs, labels)\n",
    "    return nll_loss.item()\n",
    "\n",
    "def process_batch(batch_data, batch_label, len_y, stride_y, len_x, stride_x, device, model, alpha):\n",
    "    bzq = []\n",
    "    if len(batch_data) == 0:\n",
    "        return bzq, np.array([]), {}, 0.0  # 修改 return 以包含 Brier Score 分解與 NLL\n",
    "\n",
    "    single_data_bzq_classification_record = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(0, 224 - len_y, stride_y):\n",
    "        for j in range(0, 224 - len_x, stride_x):\n",
    "            target = single_data_bzq_mask_preprocessing_imagenet(batch_data, i, j, len_x, len_y, 0)\n",
    "            targets.append(target)\n",
    "    \n",
    "    targets_tensor = torch.from_numpy(np.vstack(targets).reshape(-1, 3, 224, 224)).float().to(device)\n",
    "    predictions = model(targets_tensor)\n",
    "\n",
    "    # 計算 softmax\n",
    "    #softmax_predictions = predictions\n",
    "    softmax_predictions = F.softmax(predictions, dim=1)\n",
    "\n",
    "    labels = batch_label\n",
    "    if not isinstance(labels, torch.Tensor):\n",
    "        labels = torch.tensor(labels, device=predictions.device)\n",
    "    #print(labels)\n",
    "    # 計算 Brier Score 分解與 NLL\n",
    "    brier_components = brier_score_decomposition(softmax_predictions, labels)\n",
    "    nll_loss = compute_nll(softmax_predictions, labels)\n",
    "\n",
    "    # 計算 bzq\n",
    "    max_bzq_indices = torch.argmax(predictions, dim=1).cpu().numpy()\n",
    "    counter = Counter(max_bzq_indices)\n",
    "    most_common_num, most_common_count = counter.most_common(1)[0]\n",
    "\n",
    "    temp = softmax_predictions[:, most_common_num].cpu().numpy()\n",
    "    bzq.append(alpha * np.mean(temp) + (1 - alpha) * (2.0 / np.pi * np.arctan(1.0 / np.std(temp))))\n",
    "\n",
    "    return bzq, temp, brier_components, nll_loss\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in range(0, len(test_dataset), batch_size):\n",
    "        end = min(start + batch_size, len(test_dataset))\n",
    "        batch_data_labels = [test_dataset[i] for i in range(start, end)]\n",
    "        batch_data, batch_labels = zip(*batch_data_labels)\n",
    "        \n",
    "        for k in range(len(batch_data)):\n",
    "            if len(batch_data[k]) > 0:\n",
    "                bzq, temp, brier_components, nll_loss = process_batch(\n",
    "                    batch_data[k], batch_labels[k], len_y, stride_y, len_x, stride_x, device, model, alpha\n",
    "                )\n",
    "\n",
    "                # **儲存 Brier Score 分解**\n",
    "                bzq_list.append(bzq[-1])\n",
    "                brier_scores.append(brier_components[\"Brier Score\"])\n",
    "                uncertainties.append(brier_components[\"Uncertainty\"])\n",
    "                resolutions.append(brier_components[\"Resolution\"])\n",
    "                reliabilities.append(brier_components[\"Reliability\"])\n",
    "                nll_losses.append(nll_loss)\n",
    "\n",
    "                original_data = single_data_bzq_mask_preprocessing_imagenet(batch_data[k], 0, 0, 0, 0, 0)\n",
    "                original_prediction = model(torch.tensor(original_data.reshape(-1, 3, 224, 224)).float().to(device))\n",
    "                max_original_index = torch.argmax(original_prediction).item()\n",
    "                \n",
    "                if bzq[-1] == 0.0:\n",
    "                    if (len(bzq_list) - 1) in correct_predictions_imagenet:\n",
    "                        correct_predictions_bzq_zero_softmax_mean.append(np.mean(temp))\n",
    "                        correct_predictions_bzq_zero_softmax_std.append(np.std(temp))\n",
    "                    else:\n",
    "                        incorrect_predictions_bzq_zero_softmax_mean.append(np.mean(temp))\n",
    "                        incorrect_predictions_bzq_zero_softmax_std.append(np.std(temp))\n",
    "\n",
    "bzq_imagenet = np.array(bzq_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_bzq_imagenet = 1 / bzq_imagenet\n",
    "result_bzq_imagenet = bzq_imagenet        \n",
    "\n",
    "\n",
    "counts, bins, patches = plt.hist(bzq_imagenet, bins=bins_size)\n",
    "plt.title('Cumulative Histogram of Correct Predictions')\n",
    "plt.xlabel('bzq')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')  # 指定圖例位置\n",
    "plt.show()\n",
    "\n",
    "# 打印結果\n",
    "plt.boxplot(bzq_imagenet)\n",
    "plt.show()\n",
    "\n",
    "bzq_correct_imagenet = np.array([bzq_imagenet[i] for i in correct_predictions_imagenet])\n",
    "bzq_incorrect_imagenet = np.array([bzq_imagenet[i] for i in incorrect_predictions_imagenet])\n",
    "\n",
    "result_bzq_correct_imagenet = np.array([result_bzq_imagenet[i] for i in correct_predictions_imagenet])\n",
    "result_bzq_incorrect_imagenet = np.array([result_bzq_imagenet[i] for i in incorrect_predictions_imagenet])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate correct and incorrect predictions\n",
    "bzq_correct_imagenet = np.array([bzq_imagenet[i] for i in correct_predictions_imagenet])\n",
    "bzq_incorrect_imagenet = np.array([bzq_imagenet[i] for i in incorrect_predictions_imagenet])\n",
    "\n",
    "result_bzq_correct_imagenet = np.array([result_bzq_imagenet[i] for i in correct_predictions_imagenet])\n",
    "result_bzq_incorrect_imagenet = np.array([result_bzq_imagenet[i] for i in incorrect_predictions_imagenet])\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Cumulative Histogram of Correct Predictions\n",
    "axs[0, 0].hist(bzq_correct_imagenet, bins=bins_size)\n",
    "axs[0, 0].set_title('Cumulative Histogram of Correct Predictions')\n",
    "axs[0, 0].set_xlabel('bzq')\n",
    "axs[0, 0].set_ylabel('Count')\n",
    "axs[0, 0].legend(['Correct Predictions'], loc='upper right')\n",
    "\n",
    "# Boxplot of bzq_imagenet\n",
    "axs[0, 1].boxplot(bzq_correct_imagenet)\n",
    "axs[0, 1].set_title('Boxplot of bzq_imagenet')\n",
    "\n",
    "# Cumulative Histogram of Correct Predictions\n",
    "axs[1, 0].hist(bzq_incorrect_imagenet, bins=bins_size)\n",
    "axs[1, 0].set_title('Cumulative Histogram of Incorrect Predictions')\n",
    "axs[1, 0].set_xlabel('bzq')\n",
    "axs[1, 0].set_ylabel('Count')\n",
    "axs[1, 0].legend(['Incorrect Predictions'], loc='upper right')\n",
    "\n",
    "# Boxplot of bzq_correct_imagenet\n",
    "axs[1, 1].boxplot(bzq_incorrect_imagenet)\n",
    "axs[1, 1].set_title('Boxplot of bzq_incorrect_imagenet')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 劃出confidence-acc 圖: confidence由bzq提供，acc由該confidence數值底下預測準確的\n",
    "\n",
    "result_pred_imagenet = np.ones(len(test_dataset)) \n",
    "for i in incorrect_predictions_imagenet:\n",
    "    result_pred_imagenet[i] = 0\n",
    "\n",
    "print(sum(result_pred_imagenet))\n",
    "\n",
    "result_imagenet_dict = {}\n",
    "for i, val in enumerate(result_bzq_imagenet):\n",
    "    if val not in result_imagenet_dict.keys():\n",
    "        result_imagenet_dict[val] = [result_pred_imagenet[i]]\n",
    "    else:\n",
    "        result_imagenet_dict[val].append(result_pred_imagenet[i])\n",
    "\n",
    "# 初始化信心值和準確率列表\n",
    "confidence_values = []\n",
    "accuracies = []\n",
    "element_counts = []\n",
    "\n",
    "# 計算每個信心值範圍的準確率\n",
    "for confidence in sorted(result_imagenet_dict.keys(), reverse=True):\n",
    "    combined_results = []\n",
    "    for key in result_imagenet_dict:\n",
    "        if key >= confidence:\n",
    "            combined_results.extend(result_imagenet_dict[key])\n",
    "    element_count = len(combined_results)\n",
    "    accuracy = np.mean(combined_results)\n",
    "    confidence_values.append(confidence)\n",
    "    accuracies.append(accuracy)\n",
    "    element_counts.append(element_count)\n",
    "\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy (Rotated 60°)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values, element_counts, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Number of Elements (p(y|x) >= τ)')\n",
    "plt.title('Confidence Threshold vs Number of Elements')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "confidence_values_scaled = np.array(confidence_values)\n",
    "#confidence_values_scaled = 2 / np.pi * np.arctan(confidence_values_scaled)\n",
    "#confidence_values_scaled = confidence_values_scaled * confidence_values_scaled / (1 - confidence_values_scaled * confidence_values_scaled)\n",
    "                                                                                  \n",
    "\n",
    "#print(confidence_values_scaled)\n",
    "\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_scaled, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy (Rotated 60°)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "confidence_values_scaled = scaler.fit_transform(np.array(confidence_values_scaled).reshape(-1, 1)).flatten()\n",
    "#print(confidence_values_scaled)\n",
    "\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_scaled, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy ')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_scaled, element_counts, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#vanilla\n",
    "#original_predictions_imagenet (800000, 10)\n",
    "# 初始化信心值和準確率列表\n",
    "\n",
    "# 初始化 confidence_map_vanilla 為 defaultdict\n",
    "confidence_map_vanilla = defaultdict(list)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# 將預測結果和信心值存入字典\n",
    "for i, val in enumerate(original_predictions_imagenet):\n",
    "    conf = np.max(softmax(val))\n",
    "    confidence_map_vanilla[conf].append(result_pred_imagenet[i])\n",
    "\n",
    "print(\"finish\")\n",
    "print(len(confidence_map_vanilla))\n",
    "\n",
    "confidence_values_vanilla = []\n",
    "accuracies_vanilla = []\n",
    "element_counts_vanilla = []\n",
    "\n",
    "# 計算每個信心值範圍的準確率\n",
    "sorted_confidences = sorted(confidence_map_vanilla.keys(), reverse=True)\n",
    "combined_results_vanilla = []\n",
    "\n",
    "for confidence in sorted_confidences:\n",
    "    combined_results_vanilla.extend(confidence_map_vanilla[confidence])\n",
    "    element_count_vanilla = len(combined_results_vanilla)\n",
    "    accuracy_vanilla = np.mean(combined_results_vanilla)\n",
    "    confidence_values_vanilla.append(confidence)\n",
    "    accuracies_vanilla.append(accuracy_vanilla)\n",
    "    element_counts_vanilla.append(element_count_vanilla)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_vanilla, accuracies_vanilla, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()'''\n",
    "\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_scaled, element_counts, marker='.', linestyle='-', color='r', label='Scaled', markersize=4)\n",
    "plt.plot(confidence_values_vanilla, element_counts_vanilla, marker='.', linestyle='-', color='b', label='Vanilla', markersize=4)\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Number of Elements (p(y|x) >= τ)')\n",
    "plt.title('Confidence Threshold vs Number of Elements')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "# 繪製圖形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_vanilla, accuracies_vanilla, marker='o', linestyle='-', color='b', label='Vanilla')\n",
    "plt.plot(confidence_values_scaled, accuracies, marker='o', linestyle='-', color='r', label='Scaled')\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()'''\n",
    "\n",
    "# 假設 confidence_values_vanilla、accuracies_vanilla、confidence_values_scaled 和 accuracies 已經定義\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_values_vanilla, accuracies_vanilla, marker='.', linestyle='-', color='b', label='Vanilla', markersize=4)\n",
    "plt.plot(confidence_values_scaled, accuracies, marker='.', linestyle='-', color='r', label='Scaled', markersize=4)\n",
    "\n",
    "# 新增垂直線\n",
    "plt.axvline(x=0.6827, color='g', linestyle='--', label='x=0.6827')\n",
    "plt.axvline(x=0.9545, color='m', linestyle='--', label='x=0.9545')\n",
    "plt.axvline(x=0.9973, color='c', linestyle='--', label='x=0.9973')\n",
    "\n",
    "# 找到最接近的值\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "idx_6827_vanilla = find_nearest(confidence_values_vanilla, 0.6827)\n",
    "idx_9545_vanilla = find_nearest(confidence_values_vanilla, 0.9545)\n",
    "idx_9973_vanilla = find_nearest(confidence_values_vanilla, 0.9973)\n",
    "\n",
    "idx_6827_scaled = find_nearest(confidence_values_scaled, 0.6827)\n",
    "idx_9545_scaled = find_nearest(confidence_values_scaled, 0.9545)\n",
    "idx_9973_scaled = find_nearest(confidence_values_scaled, 0.9973)\n",
    "\n",
    "# 新增交點標記\n",
    "plt.scatter([confidence_values_vanilla[idx_6827_vanilla], confidence_values_vanilla[idx_9545_vanilla], confidence_values_vanilla[idx_9973_vanilla]], \n",
    "            [accuracies_vanilla[idx_6827_vanilla], accuracies_vanilla[idx_9545_vanilla], accuracies_vanilla[idx_9973_vanilla]], \n",
    "            color='black', zorder=5)\n",
    "plt.scatter([confidence_values_scaled[idx_6827_scaled], confidence_values_scaled[idx_9545_scaled], confidence_values_scaled[idx_9973_scaled]], \n",
    "            [accuracies[idx_6827_scaled], accuracies[idx_9545_scaled], accuracies[idx_9973_scaled]], \n",
    "            color='black', zorder=5)\n",
    "\n",
    "plt.text(confidence_values_vanilla[idx_6827_vanilla], accuracies_vanilla[idx_6827_vanilla], f'({confidence_values_vanilla[idx_6827_vanilla]:.3f}, {accuracies_vanilla[idx_6827_vanilla]:.3f})', fontsize=14, ha='left', color='blue') \n",
    "plt.text(confidence_values_vanilla[idx_9545_vanilla], accuracies_vanilla[idx_9545_vanilla], f'({confidence_values_vanilla[idx_9545_vanilla]:.3f}, {accuracies_vanilla[idx_9545_vanilla]:.3f})', fontsize=14, ha='left', color='blue') \n",
    "plt.text(confidence_values_vanilla[idx_9973_vanilla], accuracies_vanilla[idx_9973_vanilla], f'({confidence_values_vanilla[idx_9973_vanilla]:.3f}, {accuracies_vanilla[idx_9973_vanilla]:.3f})', fontsize=14, ha='left', color='blue') \n",
    "plt.text(confidence_values_scaled[idx_6827_scaled], accuracies[idx_6827_scaled], f'({confidence_values_scaled[idx_6827_scaled]:.3f}, {accuracies[idx_6827_scaled]:.3f})', fontsize=14, ha='right', color='red') \n",
    "plt.text(confidence_values_scaled[idx_9545_scaled], accuracies[idx_9545_scaled], f'({confidence_values_scaled[idx_9545_scaled]:.3f}, {accuracies[idx_9545_scaled]:.3f})', fontsize=14, ha='right', color='red') \n",
    "plt.text(confidence_values_scaled[idx_9973_scaled], accuracies[idx_9973_scaled], f'({confidence_values_scaled[idx_9973_scaled]:.3f}, {accuracies[idx_9973_scaled]:.3f})', fontsize=14, ha='right', color='red')\n",
    "\n",
    "plt.xlabel('Confidence Threshold (τ)')\n",
    "plt.ylabel('Accuracy (p(y|x) >= τ)')\n",
    "plt.title('Confidence vs Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(accuracies[idx_6827_scaled], accuracies[idx_9545_scaled], accuracies[idx_9973_scaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存儲到 .npy 檔案 \n",
    "print(random_num_for_bzq_mask_imagenet)\n",
    "'''np.save('confidence_values_vanilla.npy', confidence_values_vanilla) \n",
    "np.save('accuracies_vanilla.npy', accuracies_vanilla) \n",
    "np.save('element_counts_vanilla.npy', element_counts_vanilla)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bzq_imagenet_modified = scaler.fit_transform(np.array(result_bzq_imagenet).reshape(-1, 1)).flatten()\n",
    "print(np.sum([item for sublist in confidence_map_vanilla.values() for item in sublist]))\n",
    "#ECE calc\n",
    "\n",
    "def calculate_ece(confidences, labels, num_bins=15):\n",
    "    bin_boundaries = np.linspace(0, 1, num_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    ece = 0.0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        prop_in_bin = np.mean(in_bin)\n",
    "        if prop_in_bin > 0:\n",
    "            accuracy_in_bin = np.mean(labels[in_bin])\n",
    "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
    "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "    return ece\n",
    "\n",
    "\n",
    "print(result_bzq_imagenet)\n",
    "# 計算ECE\n",
    "ece = [calculate_ece(result_bzq_imagenet[limit * i : limit * (i + 1)], \n",
    "                     result_pred_imagenet[limit * i : limit * (i + 1)]) \n",
    "                     for i in range(80)]\n",
    "ece_modified = [calculate_ece(result_bzq_imagenet_modified[limit * i : limit * (i + 1)], \n",
    "                     result_pred_imagenet[limit * i : limit * (i + 1)]) \n",
    "                     for i in range(80)]\n",
    "\n",
    "print(\"Expected Calibration Error (ECE):\", ece)\n",
    "fig, ax = plt.subplots() \n",
    "ax.boxplot(ece) \n",
    "ax.set_title('ECE Boxplot') \n",
    "ax.set_ybound(0, 0.7)\n",
    "ax.set_ylabel('ECE') \n",
    "plt.show()\n",
    "\n",
    "print(\"Expected Calibration Error (ece_modified):\", ece_modified)\n",
    "fig, ax = plt.subplots() \n",
    "ax.boxplot(ece_modified) \n",
    "ax.set_title('ECE Boxplot') \n",
    "ax.set_ybound(0, 0.7)\n",
    "ax.set_ylabel('ECE') \n",
    "plt.show()\n",
    "\n",
    "print(ece_modified, np.mean(brier_scores), np.mean(nll_losses))\n",
    "\n",
    "print(np.percentile(ece, 25), np.percentile(ece, 50), np.percentile(ece, 75))\n",
    "print(np.percentile(ece_modified, 25), np.percentile(ece_modified, 50), np.percentile(ece_modified, 75))\n",
    "print(np.percentile(brier_scores, 25), np.percentile(brier_scores, 50), np.percentile(brier_scores, 75))\n",
    "print(np.percentile(nll_losses, 25), np.percentile(nll_losses, 50), np.percentile(nll_losses, 75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy, np.mean(brier_scores), ece_modified[0], np.mean(nll_losses))\n",
    "\n",
    "acc = [np.mean(acc_imagenet[limit * i : limit * (i + 1)]) for i in range(len(acc_imagenet) // limit)]\n",
    "#print(acc)\n",
    "val_imagenet = [[acc[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "top5_val_imagenet = [sorted(values, reverse=True)[:5] for values in val_imagenet]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(top5_val_imagenet)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy Top 5\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#print(ece_modified)\n",
    "\n",
    "val_imagenet = [[ece_modified[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 0.35)\n",
    "plt.title(\"ECE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "top5_val_imagenet = [sorted(values, reverse=False)[:5] for values in val_imagenet]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(top5_val_imagenet)\n",
    "plt.ylim(0, 0.12)\n",
    "plt.title(\"ECE Top 5\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "nll = [np.mean(nll_losses[limit * i : limit * (i + 1)]) for i in range(len(nll_losses) // limit)]\n",
    "val_imagenet = [[nll[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 12)\n",
    "plt.title(\"NLL\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "bs = [np.mean(brier_scores[limit * i : limit * (i + 1)]) for i in range(len(brier_scores) // limit)]\n",
    "val_imagenet = [[bs[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 1.2)\n",
    "plt.title(\"Brier Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [np.mean(acc_imagenet[limit * i : limit * (i + 1)]) for i in range(len(acc_imagenet) // limit)]\n",
    "#print(acc)\n",
    "val_imagenet = [[acc[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "top5_val_imagenet = [sorted(values, reverse=True)[:5] for values in val_imagenet]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(top5_val_imagenet)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy Top 5\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#print(ece_modified)\n",
    "\n",
    "val_imagenet = [[ece_modified[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 0.35)\n",
    "plt.title(\"ECE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "top5_val_imagenet = [sorted(values, reverse=False)[:5] for values in val_imagenet]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(top5_val_imagenet)\n",
    "plt.ylim(0, 0.12)\n",
    "plt.title(\"ECE Top 5\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "nll = [np.mean(nll_losses[limit * i : limit * (i + 1)]) for i in range(len(nll_losses) // limit)]\n",
    "val_imagenet = [[nll[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 12)\n",
    "plt.title(\"NLL\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "bs = [np.mean(brier_scores[limit * i : limit * (i + 1)]) for i in range(len(brier_scores) // limit)]\n",
    "val_imagenet = [[bs[idx + i * 16] for idx in range(16)] for i in range(5)]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(val_imagenet)\n",
    "plt.ylim(0, 1.2)\n",
    "plt.title(\"Brier Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
