{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.interpolate import interp1d\n",
    "import tensorflow_datasets as tfds\n",
    "from collections import Counter\n",
    "import scipy.ndimage\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import gc\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import gaussian_kde\n",
    "from numba import jit\n",
    "import torch.nn as nn\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "limit = 1000\n",
    "\n",
    "num_samples = 128  # Monte-Carlo Dropout 取樣次數\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# bzq modifying\n",
    "len_x_target = 20\n",
    "len_y_target = 20\n",
    "stride_x_target = 10\n",
    "stride_y_target = 10\n",
    "\n",
    "# mean, std proportion\n",
    "alpha = 0.5\n",
    "\n",
    "bins_size = 30  # 統計採樣數\n",
    "poly_degree = bins_size - 1\n",
    "window_size = 1\n",
    "\n",
    "#target image preprocessing\n",
    "angle = 0\n",
    "pixels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "class MCDropoutResNet(nn.Module):\n",
    "    def __init__(self, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        # **載入預訓練的 ResNet50**\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # **在 ResNet 的 feature extractor 內加入 Dropout**\n",
    "        self.dropout_layers = nn.ModuleList([\n",
    "            nn.Dropout(p=dropout_p) for _ in range(4)  # 在 layer1, layer2, layer3, layer4 之後插入 Dropout\n",
    "        ])\n",
    "\n",
    "        # **在 FC 層前加入 Dropout，但保留原始權重**\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(self.resnet.fc.in_features, 1000)\n",
    "        )\n",
    "\n",
    "        # **複製原始 FC 層的權重**\n",
    "        pretrained_resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.fc[1].weight.data = pretrained_resnet.fc.weight.data.clone()\n",
    "        self.resnet.fc[1].bias.data = pretrained_resnet.fc.bias.data.clone()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        # **遍歷 ResNet 各層並加入 Dropout**\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.dropout_layers[0](x)  # Dropout 在 layer1 之後\n",
    "\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.dropout_layers[1](x)  # Dropout 在 layer2 之後\n",
    "\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.dropout_layers[2](x)  # Dropout 在 layer3 之後\n",
    "\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.dropout_layers[3](x)  # Dropout 在 layer4 之後\n",
    "\n",
    "        # **進入 FC 層**\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def enable_dropout(self):\n",
    "        \"\"\"\n",
    "        啟用模型內的 Dropout 層，使其在推論時仍然啟動\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Dropout):\n",
    "                m.train()  # 讓 Dropout 在推論時仍作用\n",
    "    \n",
    "# 加載預訓練的ResNet50模型\n",
    "#model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model = MCDropoutResNet(dropout_p=dropout_rate).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到了bzq 正確的函數，拿來做imagenet 正確的預測\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet(original_data, start_x, start_y, len_x, len_y, magnification):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data)\n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] *= magnification\n",
    "    #new_data[start_y:start_y + len_y, start_x:start_x + len_x, :] *= magnification\n",
    "    return new_data\n",
    "\n",
    "def single_data_bzq_mask_preprocessing_imagenet_random_global(original_data, start_x, start_y, len_x, len_y, random_num_for_bzq_mask_imagenet):\n",
    "    if len_x <= 0 or len_y <= 0:\n",
    "        return original_data\n",
    "    new_data = np.copy(original_data)\n",
    "    random_num_for_bzq_mask_imagenet = random_num_for_bzq_mask_imagenet[:, :len_y, :len_x] \n",
    "    new_data[:, start_y:start_y + len_y, start_x:start_x + len_x] = random_num_for_bzq_mask_imagenet\n",
    "    return new_data\n",
    "\n",
    "bzq = []\n",
    "correct_predictions_imagenet = []\n",
    "incorrect_predictions_imagenet = []\n",
    "bzq_imagenet = []\n",
    "\n",
    "#bzq = 0的時候，提取mask之下的softmax\n",
    "correct_predictions_bzq_zero_softmax_mean = []\n",
    "correct_predictions_bzq_zero_softmax_std = []\n",
    "incorrect_predictions_bzq_zero_softmax_mean = []\n",
    "incorrect_predictions_bzq_zero_softmax_std = []\n",
    "\n",
    "# 生成隨機影像，形狀為 (limit, 3, 224, 224)\n",
    "random_images = torch.rand(limit, 3, 224, 224)\n",
    "\n",
    "# 生成存放 -1 的列表\n",
    "negative_labels = [-1] * limit\n",
    "\n",
    "# 建立 test_dataset 為 list of tuples\n",
    "test_dataset = [(random_images[i], negative_labels[i]) for i in range(limit)]\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.eval()\n",
    "predictions = []\n",
    "output = model(test_dataset[1][0].float().unsqueeze(0).to(device))\n",
    "\n",
    "softmax_output = F.softmax(output, dim=1).flatten()  # 轉換成機率\n",
    "predictions.append(softmax_output.cpu().detach().numpy())\n",
    "predictions = np.array(predictions)\n",
    "mean_pred = predictions.mean(axis=0)  # 平均預測\n",
    "mean_pred = mean_pred.flatten()\n",
    "entropy = -np.sum(mean_pred * np.log(np.clip(mean_pred, 1e-10, 1)), axis=0)  # 防止 log(0) 錯誤\n",
    "print(entropy)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "\n",
    "if dropout_rate > 0.0:\n",
    "    # 強制啟用 Dropout\n",
    "    model.enable_dropout()  # 只啟用 Dropout 層\n",
    "\n",
    "# **遍歷 test_loader 進行 Monte-Carlo Dropout**\n",
    "for inputs, _ in test_loader:  # 使用 test_loader 來獲取輸入影像\n",
    "    inputs = inputs.float().to(device)  # 移動到 GPU / CPU\n",
    "    \n",
    "    sample_predictions = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        output = model(inputs)  # 針對相同輸入取樣\n",
    "        softmax_output = F.softmax(output, dim=1)  # 轉換成機率\n",
    "        sample_predictions.append(softmax_output.cpu().detach().numpy())\n",
    "\n",
    "    predictions.append(np.stack(sample_predictions, axis=0))  # (num_samples, 1, num_classes)\n",
    "# **Monte-Carlo Dropout：計算均值與標準差**\n",
    "predictions = np.array(predictions).squeeze(axis=2)  # 形成 (test_size, num_samples, num_classes)\n",
    "\n",
    "mean_pred = predictions.mean(axis=1)  # 針對每個樣本取平均\n",
    "std_pred = predictions.std(axis=1)  # 計算標準差（不確定性指標）\n",
    "\n",
    "# **修正 entropy 計算**\n",
    "entropy_values = [entropy(mean_pred[i]) for i in range(mean_pred.shape[0])]\n",
    "\n",
    "print(entropy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[0][0].size())\n",
    "# 計算熵的分佈（分桶）\n",
    "bins = np.linspace(min(entropy_values), max(entropy_values), 15) \n",
    "hist, bin_edges = np.histogram(entropy_values, bins=bins)  # 計算直方圖數據\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # 計算每個 bin 的中心點\n",
    "\n",
    "# 繪製折線圖\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bin_centers, hist, linestyle='-', marker='o')\n",
    "\n",
    "# 設定標題與軸標籤\n",
    "plt.title(\"Entropy Distribution\")\n",
    "plt.xlabel(\"Entropy\")\n",
    "plt.ylabel(\"# of Examples\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
